# -*- coding: utf-8 -*-
"""Random Forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-dl0Bj1jQ93IDDiFt9EpbUD_CdS8ib55
"""

#!/usr/bin/env python
# coding: utf-8

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
from random import randint
from random import sample
from Adaboost import *


COLUMN_NAMES = [
    'age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan',
    'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y'
]

COLUMN_TYPES = [
    'numeric', 'categorical', 'categorical', 'categorical', 'binary', 'numeric',
    'binary', 'binary', 'categorical', 'numeric', 'categorical', 'numeric',
    'numeric', 'numeric', 'numeric', 'categorical', 'binary'
]

COLUMN_DICT = dict(zip(COLUMN_NAMES, COLUMN_TYPES))

def process_data(train_path, test_path, column_dict, column_names):
    train_data = pd.read_csv(train_path, names=column_names)
    test_data = pd.read_csv(test_path, names=column_names)

    median_dict = {}
    processed_train = pd.DataFrame()
    processed_test = pd.DataFrame()
    for column in column_names:
        if column_dict[column] == 'numeric':
            median_val = train_data[column].median()
            median_dict[column] = median_val
            processed_train[column + '>' + str(median_val)] = np.where(train_data[column] > median_val, 'yes', 'no')
            processed_test[column + '>' + str(median_val)] = np.where(test_data[column] > median_val, 'yes', 'no')
        else:
            processed_train[column] = train_data[column]
            processed_test[column] = test_data[column]

    processed_train_values = [list(processed_train.loc[i]) for i in range(len(processed_train))]
    processed_test_values = [list(processed_test.loc[i]) for i in range(len(processed_test))]

    return processed_train_values, processed_test_values

def convert_labels(labels):
    return [1 if label == 'yes' else -1 for label in labels]

def random_sample(data, labels, n_samples=None):
    if n_samples is None:
        n_samples = len(labels)
    sampled_data = []
    sampled_labels = []
    for _ in range(n_samples):
        idx = randint(0, n_samples-1)
        sampled_data.append(data[idx])
        sampled_labels.append(labels[idx])
    return sampled_data, sampled_labels

def error_bagging(forest, data, labels):
    error_count = [0] * len(forest)
    for i in range(len(labels)):
        predictions = {}
        max_count = -1
        majority_vote = None
        for j, tree in enumerate(forest):
            prediction = tree.predict(data[i])
            predictions[prediction] = predictions.get(prediction, 0) + 1
            if predictions[prediction] > max_count:
                max_count = predictions[prediction]
                majority_vote = prediction

            if majority_vote != labels[i]:
                error_count[j] += 1 / len(labels)
    return error_count

def main(num_trees, random_sizes):
    processed_train, processed_test = process_data('Data/train.csv', 'Data/test.csv', COLUMN_DICT, COLUMN_NAMES)

    training_data = [sample[:-1] for sample in processed_train]
    training_labels = convert_labels([sample[-1] for sample in processed_train])

    testing_data = [sample[:-1] for sample in processed_test]
    testing_labels = convert_labels([sample[-1] for sample in processed_test])


    forests = []
    for r in random_sizes:
        forest = []
        for _ in range(num_trees):
            sample_data, sample_labels = random_sample(training_data, training_labels)
            tree = DecisionTree(sample_data, sample_labels, attributes=[i for i in range(len(sample_data[0]))], depth=-1, feature_sample_size=r)
            forest.append(tree)
        forests.append(forest)

    for idx, forest in enumerate(forests):
        train_errors = error_bagging(forest, training_data, training_labels)
        plt.plot(train_errors, label=f"Train, size = {random_sizes[idx]}")
    plt.title("Random Forest Train Error vs Iterations", color='black')
    plt.legend()
    plt.show()

    for idx, forest in enumerate(forests):
        test_errors = error_bagging(forest, testing_data, testing_labels)
        plt.plot(test_errors, label=f"Test, size = {random_sizes[idx]}")
    plt.title("Random Forest Test Error vs Iterations", color='black')
    plt.legend()
    plt.show()

random_sizes = [2, 4, 6]
num_trees = 1000

if __name__ == "__main__":
    main(num_trees, random_sizes)