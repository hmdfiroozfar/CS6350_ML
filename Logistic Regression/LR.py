# -*- coding: utf-8 -*-
"""Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GzObfOMCYCF3iBOrStV4mA1DwgOrJeRC
"""

import numpy as np

class LogisticRegressionModel:
    def __init__(self):
        pass

    @staticmethod
    def sigmoid(z):
        return 1 / (1 + np.exp(-z))

    def predict(self, X, weights):
        return self.sigmoid(X.dot(weights)) > 0.5

    def objective_function(self, X, y, w, v):
        m = len(y)
        predictions = self.sigmoid(X.dot(w))
        prior_term = np.sum(w**2) / (2 * v)
        cost = -(1/m) * np.sum(y * np.log(predictions + 1e-15) + (1 - y) * np.log(1 - predictions + 1e-15))
        return cost + prior_term

    def objective_function_ml(self, X, y, w):
        m = len(y)
        predictions = self.sigmoid(X.dot(w))
        cost = -(1/m) * np.sum(y * np.log(predictions + 1e-15) + (1 - y) * np.log(1 - predictions + 1e-15))
        return cost

class SGDOptimizer:
    def __init__(self, model, learning_rate_initial, d):
        self.model = model
        self.learning_rate_initial = learning_rate_initial
        self.d = d

    def lr_rate_schedule(self, t):
        return self.learning_rate_initial / (1 + (self.learning_rate_initial / self.d) * t)

    def lr_rate_schedule_var(self, epoch, variance):
        adjusted_learning_rate_initial = self.learning_rate_initial / variance
        return self.lr_rate_schedule(epoch)

    def gradient(self, X, y, w, v):
        m = len(y)
        predictions = self.model.sigmoid(X.dot(w))
        return -(1/m) * X.T.dot(y - predictions) + w / v

    def gradient_ml(self, X, y, w):
        m = len(y)
        predictions = self.model.sigmoid(X.dot(w))
        return -(1/m) * X.T.dot(y - predictions)

    def SGD(self, X, y, X_test, y_test, variances, epochs):
        m, n = X.shape
        results = {}
        for v in variances:
            w = np.zeros((n, 1))
            costs = []
            for epoch in range(epochs):
                p = np.random.permutation(m)
                X, y = X[p], y[p]
                for i in range(m):
                    X_i = X[i:i+1]
                    y_i = y[i:i+1]
                    grad = self.gradient(X_i, y_i, w, v)
                    learning_rate = self.lr_rate_schedule(epoch)
                    w = w - learning_rate * grad
                cost = self.model.objective_function(X, y, w, v)
                costs.append(cost)
            train_predictions = self.model.predict(X, w)
            test_predictions = self.model.predict(X_test, w)
            train_error = np.mean(train_predictions != y)
            test_error = np.mean(test_predictions != y_test)
            results[v] = {'train_error': train_error, 'test_error': test_error, 'costs': costs}
        return results

    def SGD_ml_var(self, X_train, y_train, X_test, y_test, epochs, variance):
        m, n = X_train.shape
        weights = np.zeros((n, 1))
        costs = []
        train_errors = []
        test_errors = []
        for epoch in range(epochs):
            p = np.random.permutation(m)
            X_train, y_train = X_train[p], y_train[p]
            for i in range(m):
                X_i = X_train[i:i+1]
                y_i = y_train[i:i+1]
                grad = self.gradient_ml(X_i, y_i, weights)
                learning_rate = self.lr_rate_schedule_var(epoch, variance)
                weights -= learning_rate * grad
            cost = self.model.objective_function_ml(X_train, y_train, weights)
            costs.append(cost)
            train_pred = self.model.predict(X_train, weights)
            test_pred = self.model.predict(X_test, weights)
            train_error = np.mean(train_pred != y_train)
            test_error = np.mean(test_pred != y_test)
            train_errors.append(train_error)
            test_errors.append(test_error)
        return weights, costs, train_errors, test_errors

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def plot_cost_curve(variances, results):
    plt.figure(figsize=(10, 6))
    for v in variances:
        plt.plot(results[v]['costs'], label=f'Variance: {v}')
    plt.xlabel('Epochs')
    plt.ylabel('Cost')
    plt.title('Cost Curve per Variance')
    plt.legend()
    plt.show()

# Load and preprocess data
train_data = pd.read_csv('train.csv', header=None)
test_data = pd.read_csv('test.csv', header=None)
X_train = np.c_[np.ones((train_data.shape[0], 1)), train_data.iloc[:, :-1].values]
y_train = train_data.iloc[:, -1].values.reshape(-1, 1)
X_test = np.c_[np.ones((test_data.shape[0], 1)), test_data.iloc[:, :-1].values]
y_test = test_data.iloc[:, -1].values.reshape(-1, 1)

# Initialize model and optimizer
model = LogisticRegressionModel()
learning_rate_initial = 0.1
d = 0.5
epochs = 100
sgd_optimizer = SGDOptimizer(model, learning_rate_initial, d)

V = [0.01, 0.1, 0.5, 1, 3, 5, 10, 100]

print("MAP Estimation: ")
map_results = sgd_optimizer.SGD(X_train, y_train, X_test, y_test, V, epochs)
for v, res in map_results.items():
    print(f'Variance: {v}, Training Error: {res["train_error"]}, Testing Error: {res["test_error"]}')
plot_cost_curve(V, map_results)

print("ML Estimation: ")
ml_results = {}
for variance in V:
    weights_ml, costs_ml, train_errors_ml, test_errors_ml = sgd_optimizer.SGD_ml_var(X_train, y_train, X_test, y_test, epochs, variance)
    ml_results[variance] = {'weights': weights_ml, 'costs': costs_ml, 'train_errors': train_errors_ml, 'test_errors': test_errors_ml}
    print(f'Variance: {variance}, Train Error: {train_errors_ml[-1]}, Test Error: {test_errors_ml[-1]}')

plot_cost_curve(V, ml_results)